#ifdef __cplusplus
extern "C" {
#endif
/* Version 0.0
** From "Wayne's Little DSA Library" (DSA == Data Structures and
** Algorithms) Feel free to change, modify, or burn these sources, but if
** you modify them please don't distribute your changes without a clear
** indication that you've done so.  If you think your change is spiffy,
** send it to me and maybe I'll include it in the next release.
**
** Wayne Hayes, wayne@cs.utoronto.ca (preffered), or wayne@cs.toronto.edu
*/

#include "Misc.hpp"
#include "Stats.hpp"
#include "Rand48.hpp"
#include <assert.h>
#include <math.h>
#include <string.h>

STAT *StatAlloc(int numHistogramBins, double histMin, double histMax,
    Boolean geom, Boolean allData)
{
    STAT *s = (STAT*)Calloc(1, sizeof(STAT));
    s->n = 0;
    s->geom = geom;
    s->sum = s->sum2 = s->sum3 = s->geomSum = s->geomSum2 = s->geomSum3 = 0.;
    s->min = 1e30;
    s->max = -1e30;
    if(numHistogramBins)
    {
	s->histogram = (int*)Calloc(1, (numHistogramBins+2) * sizeof(int));
	++s->histogram; /* make the base -1 */
	s->numHistBins = numHistogramBins;
	s->histMin = histMin;
	s->histWidth = histMax-histMin;
	s->histCumulative = false;
    }
    if(allData) {
	s->allData = (double*)Calloc(DATA_SIZE_INIT, sizeof(double));
	s->dataSize = DATA_SIZE_INIT;
    }
    return s;
}

COVAR *CovarAlloc(void)
{
    COVAR *c = (COVAR*)Calloc(1, sizeof(COVAR));
    c->n = 0;
    c->sumX = c->sumY = c->sumXY = 0.;
    return c;
}
COVAR *CovarReset(COVAR *c)
{
    c->n = 0;
    c->sumX = c->sumY = c->sumXY = 0.;
    return c;
}
int CovarAddSample(COVAR *c, double x, double y)
{
    c->n++;
    c->sumX += x;
    c->sumY += y;
    c->sumXY += x*y;
    return c->n;
}
double Covariance(COVAR *c)
{
    assert(c->n > 1);
    return (c->sumXY - (c->sumX * c->sumY)/c->n)/(c->n-1);
}
void CovarFree(COVAR*c){Free(c);}

static int CmpDouble(const void *a, const void *b)
{
    const double *x = (const double*)a, *y = (const double*)b;
    return (*x)-(*y);
}

static STAT *DataSort(STAT *s)
{
    assert(s->allData);
    if(s->dataSorted) return s;
    qsort(s->allData, s->n, sizeof(s->allData[0]), CmpDouble);
    s->dataSorted = true;
    return s;
}

double StatECDF(STAT *s, double z)
{
    DataSort(s);
    if(z < s->allData[0]) return 0; // CDF is zero to the left of smallest element
    if(z > s->allData[s->n-1]) return 1; // CDF is one to the right of largest element
    void *v = bsearch((void*)&z, (void*)s->allData, s->n, sizeof(s->allData[0]), CmpDouble);
    double *x = (double *)v, *x1, *x2;
    int i = x - s->allData; // index of element found
    assert(0<=i && i<s->n);
    // following two loops find the *lowest* value that works
    until(i==s->n-1 || s->allData[i+1]>=z) {assert(i < s->n-1); ++i;}
    until(i==0 || s->allData[i]<=z) {assert(i>0); --i;}
    assert(0 <= i && i < s->n);
    x = s->allData + i;
    assert(*x == s->allData[i]);
    if(*x == z) return i*1.0/s->n; // exactly at one of the points
    else if(*x < z) {x1=x; assert(i+1<s->n); x2=x+1; assert(x2-(s->allData) < s->n);}
    else {assert(*x > z); x2=x; assert(i>0);      x1=x-1; assert(x1-(s->allData) >= 0  );}
    assert(*x1<=z && z<=*x2);
    double frac=(z-*x1)/(*x2-*x1), h1=(double)(x1-s->allData)/s->n, h2=(double)(x2-s->allData)/s->n;
    return h1 + frac*(h2-h1);
}

static double fact(int k)    {if(k<=0)return 1; else return k*fact(k-1);}
static double logFact(int k) { if(k<=0)return 0; else return (log(k)+logFact(k-1));}
static double fact2(int k)    {if(k<=1)return 1; else return k*fact2(k-2);}
static double logFact2(int k) {if(k<=1)return 0; else return log(k)+logFact2(k-2);}

double HalfGamma(int k) {return sqrt(M_PI) *   fact2(k-2)/IntPow(sqrt(2.0),(k-1));}
double logHalfGamma(int k){return log(sqrt(M_PI))+logFact2(k-2)-(k-1)*log(sqrt(2));}
double Gamma(double x)    {if(x==(double)(int)(x)) return    fact((int)(x-1));if(2*x==(double)(int)(2*x))return    HalfGamma(2*(int)x); else Fatal("Gamma only implemented for integers and half-integers, but given %g", x);return 0;}
double logGamma(double x) {if(x==(double)(int)(x)) return logFact((int)(x-1));if(2*x==(double)(int)(2*x))return logHalfGamma(2*(int)x);else Fatal("Gamma only for integers and half-integers"); return 0;}

double    Chi2_pair2(int df, double X2){assert(df%2==0); return    IncGamma(df/2,X2/2) /  Gamma(df/2);}
double logChi2_pair2(int df, double X2){assert(df%2==0); return logIncGamma(df/2,X2/2)-logGamma(df/2);}
double    Chi2_pair (int df, double X2){return df%2==0 ? Chi2_pair2(df,X2) : sqrt(Chi2_pair2(df-1, X2)*Chi2_pair2(df+1,X2));}
double logChi2_pair (int df, double X2){return df%2==0 ? logChi2_pair2(df,X2) : (logChi2_pair2(df-1, X2)+logChi2_pair2(df+1,X2))/2;}

double IncGamma(int s, double x)
{
    assert(s>=1);
    if(s==1)return Exp(-x);
    else return (s-1)*IncGamma(s-1,x) + IntPow(x,(s-1))*Exp(-x);
}

double logIncGamma(int s, double x)
{
    assert(s>=1);
    if(s==1)return -x;
    else {
        assert(x>0);
        double log_a = log(s-1.0) + logIncGamma(s-1,x), log_c = (s-1)*log(x)-x;
        return LogSumLogs(log_a,log_c);
    }
}


PEARSON *PearsonAlloc(void)
{
    PEARSON *p = (PEARSON*)Calloc(1, sizeof(PEARSON));
    return p;
}

void PearsonReset(PEARSON *p){
    p->sumX=p->sumY=p->sumX2=p->sumY2=p->sumXY=p->n=0;
}

int PearsonAddSample(PEARSON *p, double x, double y)
{
    p->computeValid=false;
    p->sumX+=x;
    p->sumY+=y;
    p->sumX2+=x*x;
    p->sumY2+=y*y;
    p->sumXY+=x*y;
    return ++(p->n);
}

static double Pearson2T(int n, double r){if(r==1)return 1e30; else return r*sqrt((n-2)/(1-r*r));}

static double NormalPhi(double x)
{
    double arg=-x*x/2;
    if(arg < -744) {
	static int numWarn;
	if(numWarn++ < 10) Warning("NormalPhi: Exp(%g) too small to represent (warning #%d)", arg, numWarn);
	else if(numWarn == 10) Warning("NormalDist: Exp(%g) too small to represent (further warnings supressed)", arg);
#if 0 // set to 1 if you want to return something smallest representable rather than zero.
	return 1e-323; // smallest representable, non-normalized FP number
#endif
    }
    return Exp(arg)/2.506628274631000502415765284811;
}

static double NormalDist(double mu, double sigma, double x){
    double X = (x-mu)/sigma;
    return NormalPhi(X);
}

Boolean PearsonCompute(PEARSON *p)
{
    if(!p->n)return false;
    if(p->computeValid) return false;
    double numer=p->sumXY-p->sumX*p->sumY/p->n;
    double D1=p->sumX2-p->sumX*p->sumX/p->n;
    double D2=p->sumY2-p->sumY*p->sumY/p->n;
    //fprintf(stderr, "%g %g\n",D1,D2);
    double denom=sqrt(D1*D2); p->rho=0; if(denom)p->rho=numer/denom;
    p->t=Pearson2T(p->n,p->rho);
    if(p->t<0)p->t=-p->t;
    // Fisher R-to-z
    double z=0.5*log((1+p->rho)/(1-p->rho));
    double zse=1/sqrt(p->n-3), F;
    p->p = F = 2*MIN(NormalDist(0,zse,z),NormalDist(0,zse,-z));
    // We seem to be at least 100x too small according to Fisher
    if(p->p > 1) p->p = 1-1/(p->p);
    return (p->computeValid=true);
}

char *PearsonPrint(PEARSON *p) {
    static char buf[BUFSIZ];
    if(!p->computeValid) PearsonCompute(p);
    sprintf(buf, "%d\t%.3g\t%.3g\t%.3g", p->n, p->rho, p->p, p->t);
    return buf;
}

void PearsonFree(PEARSON *p){ Free(p);}

STAT *StatReset(STAT *s)
{
    s->n = 0;
    s->sum = s->sum2 = s->sum3 = s->geomSum = s->geomSum2 = s->geomSum3 = 0.;
    if(s->numHistBins)
    {
	memset(s->histogram - 1, 0, (s->numHistBins+2) * sizeof(int));
	s->histCumulative = false;
    }
    if(s->allData) {
	Free(s->allData);
	s->allData = (double*)Calloc(DATA_SIZE_INIT, sizeof(double));
	s->dataSize = DATA_SIZE_INIT;
    }
    return s;
}

void StatFree(STAT *s)
{
    if(s->numHistBins)
	Free(s->histogram-1);   /* since we bumped it up before */
    if(s->allData) Free(s->allData);
    Free(s);
}


static void ToggleHistType(STAT *s)
{
    int i;
    if(!s->histCumulative)	/* make it cumulative */
    {
	s->histCumulative = true;
	for(i=0; i <= s->numHistBins; i++)
	    s->histogram[i] += s->histogram[i-1];
    }
    else
    {
	s->histCumulative = false;
	for(i=s->numHistBins; i >= 0; i--)
	    s->histogram[i] -= s->histogram[i-1];
    }
}


void StatAddSample(STAT *s, double sample)
{
    s->sum += sample;
    s->sum2 += sample * sample;
    s->sum3 += sample * sample * sample;
    if(sample > s->max)
	s->max = sample;
    if(sample < s->min)
	s->min = sample;
    if(s->geom)
    {
	if(sample > 0)
	{
	    double ls = log(sample);
	    s->geomSum += ls;
	    s->geomSum2 += ls*ls;
	    s->geomSum3 += ls*ls*ls;
	}
	else
	    Warning("StatAddSample(geom): sample %g <= 0", sample);
    }
    if(s->numHistBins)
    {
	int histBin = s->numHistBins *
	    (sample - s->histMin)/s->histWidth;
	if(s->histCumulative)
	    ToggleHistType(s);
	if(histBin < 0)
	    ++s->histogram[-1];
	else if(histBin >= s->numHistBins)
	    ++s->histogram[s->numHistBins];
	else
	    ++s->histogram[histBin];
    }
    if(s->allData) {
	assert(s->n <= s->dataSize);
	if(s->n == s->dataSize){
	    s->dataSize *= 2;
	    s->allData = (double*)Realloc(s->allData, s->dataSize * sizeof(double));
	}
	s->allData[s->n] = sample;
	s->dataSorted = false;
    }
    s->n++;
}

void StatDelSample(STAT *s, double sample)
{
    s->sum -= sample;
    s->sum2 -= sample*sample;
    s->sum3 -= sample * sample * sample;
    if(sample <= s->min)
    {
	if(sample < s->min)
	    Warning("StatDelSample: deleted sample is less than the observed minimum!");
	else
	    Warning("StatDelSample: can't update minimum when it's the deleted sample");
    }
    if(sample >= s->max)
    {
	if(sample > s->max)
	    Warning("StatDelSample: deleted sample is greater than the observed maximum!");
	else
	    Warning("StatDelSample: can't update maximum when it's the deleted sample");
    }
    if(s->geom)
    {
	if(sample > 0)
	{
	    double ls = log(sample);
	    s->geomSum -= ls;
	    s->geomSum -= ls*ls;
	    s->geomSum -= ls*ls*ls;
	}
	else
	    Warning("StatDelSample(geom): sample %g <= 0", sample);
    }
    if(s->numHistBins)
    {
	int histBin = s->numHistBins *
	    (sample - s->histMin)/s->histWidth;
	if(s->histCumulative)
	    ToggleHistType(s);
	if(histBin < 0)
	    --s->histogram[-1];
	else if(histBin >= s->numHistBins)
	    --s->histogram[s->numHistBins];
	else
	    --s->histogram[histBin];
    }
    if(s->allData) Apology("StatDeleteSample: cannot delete samples when allData is true--it's too expensive");
    s->dataSorted = false;
    s->n--;
}

int *StatHistogram(STAT*s)
{
    if(s->histCumulative)
	ToggleHistType(s);
    return s->histogram;
}

int *StatCumulativeHistogram(STAT*s)
{
    if(!s->histCumulative)
	ToggleHistType(s);
    return s->histogram;
}


double StatMean(STAT*s)
{
    return s->sum / s->n;
}

double StatGeomMean(STAT*s)
{
    return exp(s->geomSum / s->n);
}

double StatVariance(STAT*s)
{
    /* unbiased estimator, Law & Kelton eqn 4.4; take ABS since if it's zero then roundoff sometimes makes it negative */
    return fabs(s->sum2 - s->sum*s->sum / s->n) / (s->n - 1);
}

double StatGeomVariance(STAT*s)
{
    return exp((s->geomSum2 - s->geomSum*s->geomSum / s->n) / (s->n - 1));
}

double StatStdDev(STAT*s)
{
    return sqrt(StatVariance(s));
}

double StatGeomStdDev(STAT*s)
{
    return exp(sqrt(log(StatGeomVariance(s))));
}

double StatSkew(STAT*s)
{
    /* this is probably not unbiased; Law & Kelton p.290.  I've substituted
    ** Xbar for mu (tsk, tsk), and expanded the E[(x-mu)^3] so I can use
    ** running sums.
    */
    double mu = s->sum / s->n;
    double sd = StatStdDev(s);
    return ((s->sum3 + 3*mu*s->sum2)/s->n + 4*mu*mu*mu) / (sd*sd*sd);
}

double StatConfInterval(STAT *s, double confidence)
{
    return StatTDistP2Z((1-confidence)/2, s->n - 1) * sqrt(StatVariance(s) / s->n);
}


double StatRV_Normal(void)
{
    static int which;
    static double next;
    double fac, rsq, v1, v2;

    if(!which)
    {
	do {
	    v1 = 2*drand48()-1;
	    v2 = 2*drand48()-1;
	    rsq = SQR(v1)+SQR(v2);
	} while(rsq >= 1 || rsq == 0);
	fac=sqrt(-2*log(rsq)/rsq);
	next = v1*fac;
	which = 1;
	return v2*fac;
    }
    else
    {
	which = 0;
	return next;
    }
}


/* Taken from MacDougall, "Simulating Computer * Systems", MIT Press, 1987,
 * p. 276 (or therabouts.)
 */
static double NormalPtoZ(double quantile)
{
    double    q, z1, n, d;

    q = quantile > 0.5 ? (1 - quantile) : quantile;
    z1 = sqrt (-2.0 * log (q));
    n = (0.010328 * z1 + 0.802853) * z1 + 2.515517;
    d = ((0.001308 * z1 + 0.189269) * z1 + 1.43278) * z1 + 1.0;
    z1 -= n / d;
    return (quantile > 0.5 ? -z1 : z1);
}


/*
 * TDist (double quantile, long freedom) computes the given upper quantile
 * of the student t distribution with "freedom" degrees of freedom.  This
 * is the x for which the area under the curve from x to +ve infinity is
 * equal to quantile.  Taken from MacDougall, "Simulating Computer
 * Systems", MIT Press, 1987, p. 276.  Note it's a one-tailed z-value.
 */

double StatTDistP2Z(double quantile, long freedom)
{
    long    i;
    double    z1, z2, h[4], x;

    z1 = fabs (NormalPtoZ (quantile));
    z2 = z1 * z1;

    h[0] = 0.25 * z1 * (z2 + 1.0);
    h[1] = 0.010416667 * z1 * ((5.0 * z2 + 16.0) * z2 + 3.0);
    h[2] = 0.002604167 * z1 * (((3.0 * z2 + 19.0) * z2 + 17.0) * z2 - 15.0);
    h[3] = z1 * ((((79.0 * z2 + 776.0) * z2 + 1482.0) * z2 - 1920.0) * z2 - 945.0);
    h[3] *= 0.000010851;

    x = 0.0;
    for(i = 3; i >= 0; i--)
    x = (x + h[i]) / (double) freedom;
    z1 += x;
    return (quantile > 0.5 ? -z1 : z1);
}


///////////////////////////////////////////////////////////////////////////
// Now the ACM algorithms, which may or may not be more accurate???
///////////////////////////////////////////////////////////////////////////
static double StatACMGaussZ2P(double z)
{
  // input = z-value (-inf to +inf)
  // output = p under Normal curve from -inf to z
  // e.g., if z = 0.0, function returns 0.5000
  // ACM Algorithm #209
  double y; // 209 scratch variable
  double p; // result. called 'z' in 209
  double w; // 209 scratch variable

  if (z == 0.0)
    p = 0.0;
  else
  {
    y = fabs(z) / 2;
    if (y >= 3.0)
    {
      p = 1.0;
    }
    else if (y < 1.0)
    {
      w = y * y;
      p = ((((((((0.000124818987 * w
        - 0.001075204047) * w + 0.005198775019) * w
        - 0.019198292004) * w + 0.059054035642) * w
        - 0.151968751364) * w + 0.319152932694) * w
        - 0.531923007300) * w + 0.797884560593) * y * 2.0;
    }
    else
    {
      y = y - 2.0;
      p = (((((((((((((-0.000045255659 * y
        + 0.000152529290) * y - 0.000019538132) * y
        - 0.000676904986) * y + 0.001390604284) * y
        - 0.000794620820) * y - 0.002034254874) * y
        + 0.006549791214) * y - 0.010557625006) * y
        + 0.011630447319) * y - 0.009279453341) * y
        + 0.005353579108) * y - 0.002141268741) * y
        + 0.000535310849) * y + 0.999936657524;
    }
  }

  if (z > 0.0)
    return (p + 1.0) / 2;
  else
    return (1.0 - p) / 2;
} // StatACMGaussZ2P()
double StatACMStudentZ2P_D(double t, double df)
{
  // for large int df or double df
  // adapted from ACM algorithm 395
  // returns 1-tail probability

  double n = df; // to sync with ACM parameter name
  double a, b, y;

  t = t * t;
  y = t / n;
  b = y + 1.0;
  if (y > 1.0E-6) y = log(b);
  a = n - 0.5;
  b = 48.0 * a * a;
  y = a * y;

  y = (((((-0.4 * y - 3.3) * y - 24.0) * y - 85.5) /
    (0.8 * y * y + 100.0 + b) +
      y + 3.0) / b + 1.0) * sqrt(y);
  return StatACMGaussZ2P(-y);
} // StatACMStudentZ2P_D (double df)
double StatACMStudentZ2P(double t, int df)
{
  // adapted from ACM algorithm 395
  // forsmall int df
  int n = df; // to sync with ACM parameter name
  double a, b, y, z;

  z = 1.0;
  t = t * t;
  y = t / n;
  b = 1.0 + y;
#if 0 //The Z2P_D function doesn't seem to work.
  if ((n >= 1000 && t < n) || n > 1000) // large df
  {
    double x = 1.0 * n; // make df a double
    return StatACMStudentZ2P_D(t, x); // double version
  }
#endif
  if (n < 1000 && t < 4.0)
  {
    a = y = sqrt(y);
    if (n == 1)
      a = 0.0;
  }
  else
  {
    int j;
    a = sqrt(b);
    y = a * n;
    for(j = 2; a != z; j += 2)
    {
      z = a;
      y = y * (j - 1) / (b * j);
      a = a + y / (n + j);
    }
    n = n + 2;
    z = y = 0.0;
    a = -a;
  }

  int sanityCt = 0;
  while (true && sanityCt < 10000)
  {
    ++sanityCt;
    n = n - 2;
    if (n > 1)
    {
      a = (n - 1) / (b * n) * a + y;
      continue;
    }

    if (n == 0)
      a = a / sqrt(b);
    else // n == 1
      a = (atan(y) + a / b) * 0.63661977236; // 2/Pi

    return (z - a)/2;
  }

  assert(false);  // shouldn't get here
} // StatACMStudentZ2P (int df)


#if TEST
int main(void)
{
    int v;
    double gamma;
    puts("Enter3 df, gamma pairs until you're happy (see Law&Kelton, Appendix)");
    while(scanf("%d %lf", &v, &gamma) == 2)
	printf("%g\n", StatACMStudentZ2P(StatTDistP2Z(gamma, v),v));
    return 0;
}
#endif
#ifdef __cplusplus
} // end extern "C"
#endif
